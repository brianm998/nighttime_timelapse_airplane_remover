Here is a description of the algorithm used to detect airplane streaks in timelapse images.


Each image from the video sequence is processed with one or two adjecent frames.

Only the first and last frames are processed with one adjecent frame.

The first step in processing is to identify outlying pixels.  These are pixels that have brightened by a specific amount from the adjecent frames.

Then these outliers are gathered into groups of direct neighbors, ignoring groups that are too small. 

Then each identified outlier group is categorized as either likely an airplane or not, based upon a number of criteria.

A Hough Transform is run on each outlier group separately from the rest of the image.  The resulting list of lines is part of the analysis.

In addition, the size of each outlier group, the number of pixels it fills within its bounding box (fill rate), the aspect ratio of its bounding box, and the brightness level of the group compared to the adjecent frames are all included.

This set of data about each outlier group is then ranked based upon histograms generated from data via the outlier data process outlined in outlier_data_process.txt.  More data here is always helpful.

Each frame can be processed in parallel until this point.  There is a single thread which compares frames with eachother, after the outlier groups have been identified and initially categorized.  This thread looks at each frame and some number of adjecent frames, comparing the outlier groups and potentially making changes based upon how the frames relate to eachother.

After the final paintability of each outlier group has been decided for a particular frame, it is then put into a final queue which handles painting over the identified airplane streaks, and saving the output file. 
